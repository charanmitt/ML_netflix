{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gumagau/almabetter-final-project-netflix-unsupervised/blob/main/Copy_of_Netflix_Movies_And_Tv_Shows_Clustering_ipynb_Gautam_Mohanty_resubmitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um1LMDO3-bMi"
      },
      "source": [
        "#**Project Name : Netflix Movies and TV Shows Clustering**\n",
        "# Project Type unsupervised ML\n",
        "\n",
        "# Batch : Cohort Seoul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MhwKpmHZxoZ"
      },
      "source": [
        "# **Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUD0WW7VZ2g4"
      },
      "source": [
        " The problem statement revolves around improving the Netflix experience for users by understanding their preferences and viewing habits. By analyzing data on what users watch and how they interact with the platform, the goal is to enhance Netflix's recommendation algorithms. This can lead to better personalized recommendations, ultimately increasing user satisfaction and engagement with the platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dAThVKMrWM_"
      },
      "source": [
        "# Project summary\n",
        "\n",
        "**With more than 83 million subscribers and presence in more than 190 countries, Netflix is the most popular Internet television network in the world. Its users watch more than 125 million hours of TV and movie content daily, including original series, documentaries, and feature films. On almost any screen that is linked to the Internet, members can watch as much as they want, whenever and wherever. Without interruptions or obligations, members can play, pause, and resume watching at any time.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lUnueUi0Ck0"
      },
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASoAAACpCAIAAAATC+e6AAASiElEQVR4nO3de4wd1X0H8O/vnHneu7PrtbHBxtBiCQWrrVGaxoBoVRESEqA8QkStQlSlJVKKGvpHK1VqIlVqlT6l5I/2j+aP9o8kEMVEbSkk1E4Ug2hpQ5uS8mgIxaAGA7axvWvv4z7mcX79Y7zL7r0zd6/33uXMLL+Prix5997ZuTPnO49zzpxDzAwhhA3K9goI8d4l8RPCGomfENZI/ISwRuInhDUSPyGskfgJYY3ETwhrJH5CWCPxE8IaiZ8Q1kj8hLBG4ieENRI/IayR+AlhjcRPCGskfkJYI/ETwhqJnxDWSPyEsEbiJ4Q1Ej8hrJH4CWGNxE8IayR+Qlgj8RPCGomfENZI/ISwRuInhDUSPyGscUb58Pz8/GOPPjauVRGidm67/bYoitb9cRplfr+33nrr0ksv3Toxue4lCFFfMwtzb7755q5du9a9hJHOfgAmvWDLtq0jLkSIOkrjeMQlyL2fENZI/ISwRuInhDUSPyGskfgJYY3ETwhrJH5CWCPxE8IaiZ8Q1kj8hLBG4ieENRI/IayR+AlhjcRPCGskfkJYI/ETwhqJnxDWSPyEsEbiJ4Q1Ej8hrJH4CWGNxE8Ia0YdaHC8GJghLBb9ajsjHPjZMyUfbAJbGVT0t471//TCNYFtq4dKLVuT9YmA6RXLH7CJLkj/ZpkjnC1582VFG3B4beBUyecvYXh9PxywJmV7c6VZwnzJr7YAk+sf13b8KhQ/BiLDf7nQDYpG/j3Y8A55umzbzRH+fL67OzP9vzpL9IeTAWPVPsv/+/DZjotR98a8UvdP+ssJHLAm6+ACP3b0XzS9/NCTr/ZYln+W6AtRENP5zdIGfqOd3NhNk6I3/85U2LMBh9cGbkmyu1tx4ZK/OBEc1bQygXOE+9rJDSVr8oZWfzzhDzgQnyH80UJ8VZr1fzzfmF+Y8KqTwArFD4DL2N9Nw76i5TC7wINeY7IkLQmwL872xllKvYXkhC4tNtd1UwB6tJ0xo8y5yWDb0oqdBfbF2ZXJeOLnMCNEQghXrOR1nXRXNmoJOqHJBcdLmeoQ9qTmF1tpS/Vurmy0a4QO4fLU7G+n/bsmIzSbvbkOGC86+vfOdfsXlRGuN+nB0OtJ7DIGLjN892LsFm2ehuEnpqtV4Ku1NgmhDfKIewpvRrQ3zvZlZl717UMAwCIQK0qJktW/VoABEsAt+lRMcBhmhOKlgE7fx2NFGWE8+QP1HMUZWFSUmd5NdEGWNsuqVe8SxYSk7+ukVLoBh9Qi9O+afMlx3/70gG+7+n98fVVccIpPiQ604/ujYE/RJdJZwqfaaWi43XcQUcBrrno4cKPKnPpQl6oXA2xLeV9mOrbXZBieqdIerqGdzA82vajoDJ8Rru+ke4pmJmFgC+PAQtyfPQC+4UMN9xiNdBM7dvWIH4CWogOt+HjxyU9sKgHwuKuPuqq/dBpgT2J+Jc76D8TzhF/tJDuK7ooV8LZWXw3dyyp2YKxN/BLCvjjbl5lRZ7UQlUfAcaJjriq8LZ/XdEu74ECcAb+2EHdLTn1PhM6xkjsXi2oTPwBRxjfHaf+9lth8djJ/reE5RTd4BtgbZ+8zq343R7g1znZlxbfEXUUHQ69Sd325OsUvJbq9VVgdPWZq6Jfm4i2Y/7z/daF/Ma/yfddWuzpC4IinnwucwjrMKON7OsnZFQfiDLhvsfjCKDT8ROj+q1NcWWpXtWo+B0sIVybm/Sm/VFLvPBYKOEd0pry5okesyFnRHNIEZjS9UlK8d2fG6StPA/5i0/AposIiOOJqz69ueKigBHjKd67upEnfNWNX0YfbyZfD84cmBi7L+Ko4669czf2L72yv3qkP9Ypf7q7yeuex8A0/Oul9rukNv8NW3tBvZdw/FWZFbztO9N+nFrb3rblv+Nmme89ksLPoS2kgGGIdNOPZ0ClbSOFi3fW2pL87tjK+GTifni9YRwNcmZhrUvOMo0JghnB/J/FL2hve1uoRTw+zDd99NYtfXu98xQSvuxPGMCLDW7BGH7cyhIJeVLlpMJba3Hq4zBeB1/cXVy7EGXkh1UHAMUVHAufWVlLYlnDfYveRLY0rmC8xuH2x+D2+4YNTfmt1v4XqqPgtQK+83vn6pKDeeYy6G1NDNrihvPCEeaHSSp/PLljE+Eaj+GiWEfbF2bWZmSHc2R3U3vD1wN1ayeyhdvED0FL00XZS1oVXbCYecNhVL3m6sAEwyvjmbnoONLi94VVV3WNS/eKXEK6Os+08cl9pUQcp6HlPFzYAdhXdsRjfmpS2N7QVfaXhXVLhglK/+AHYnZo746zonlxsNlcwf6XhFXb7NsA085+dbRf+NjR8JHA2tJJ8dLWMH4BfKnkgRWwyBLys6Qe+Dot60nqM7eW9z58M3UaFT32oafzain65nVxi5PrzveIp3+l/XgmAKanQUsAbjvqHqrY3LKtl/AC4jPva8Yxcf74HTDMeDNwBz2328w0/NOGZajdsor7xA/DBOBvlIbQB/A1r038X8FqvOuoQDjXcqeEeMj7f1O672yr/bWvW7L4sIVzdSX825bIHn0cxr+g06PTqI2dPz7KoaJASuwLmazMzoGOxx/ySoza0x8IGaTIe99179VCPu/iGn5hwX1W4XOK3cfIHnx+I/PFu5a6im1rJ3iTD6ke8/dV/5U+j4Kiu0AMsCeEXutmjnUGDMDUMf3zHRMUrAwt5wJOOesHXV3fXHuWmrehvQ69qj/YVqnH8MsJ1nTSNgvFeUhngYsO7Omv0QvEmOEG1yrHBGgNnxIT6VhdfBP6e7+xvp4Wdy5aFhg9OeEcdqv6VJ2p972eA7YZvTbL2Biw5oTVe/YOUVJ9XhxJZJmIc9pz5ISpgnvadirc3LKtN/ApXNDT8ka6dB3C9OlfP1BEBP9L0dOAWNgDm8vaGxyrf3rCsHvFTwGuOSvti1lb0sVbSlCC8N2xnPBy6hd07c77hr014qj51S/WIn2a85hR3vd1q+LY422Q9/UWhEHjCVc/5uvD5YwW87qi/D9wt9Tkc1yN+ADTRM57jF114fKRtoUKhjvd+cf1WucAliSns5KkZs46aq9hQgoPVJn6RMf/sF9TTJoRruumQj3gPSQEur/FqVu/eTwGh4QEvj0caLde6WcJvtZOy5xvypuAPxVmNxsKrTcODC3xfq5c8fWVieob0CA3fmGQLYzroKeCkomOuwtI40J0VNxsZMwBNdEJRpYqyy3gm0H8SBYOb3V+v2GpfEA0MHmurq+g3W/HDWxobNxbJeNUmfrnnPd0/fUJX0SdLZvBYB9/wdya832/6g9+2m7lSjX4A5pX6vlZXMJdvCqr4+C4DtIEPxdneOBvQ7pePQXhtZt5Q1WqSLVOz+B0MvU8sFpSun47NGU0jTgayzGNcBK7OPDhDcpkxcLCZWjtOdGenYJ6WHlHG+1Nz1Ne1aOSszb1f7kWHng16K74MMMW8JzVjmtVEVE4MfCA113eSNY+wKdHHx3cptNFqFj8A3/Od/sGPy577EptDh3B7nG5L157XKSH8TDfbn3ItKmBqFr/hex6JzcRlHFiIzw293+9qxyfqUEZqFj8Cntfqv7ziscfFpjRL+PVOsnXoadsywg3t9CpTg9rPmsUPwE7mJ0O3cPINsSkFvEZ7Qw8D7MjMzd20+oNx1S9+AfC8VoOfOhGbRhu4Mcn2lszfUDZxTVfRna3kdOUbWeoXPwJ+6NALJR3/xCZznOhAKy5sb1DAKUUxFRRiA+xJzZ1J1XvA1C9+ABTweLgpG7cqKrPUWM/AB1KzL84K2xuijP9gS1g2CG+U8fuTrOKzQdYyflsY3/J0e+PXfeUIRTEQA22gDcwR5gizhFnCXLV38FhMcu93X7kFZpf+2wbGe7Y5W97eoICjrnrGVc96xV1H5jXdsVj1BsCa9XrJETBLeMovnftmRDHhNCghbjBCwGX4zA0gYkwbEwFNRmjMNsMew2f+XORPb94rYY9x5NTCPFFMMMCso7qEFmiRsKCoSxQTziiaUyomvKrUT8Y0BA4DQXl7g2Y8GbqnQV8P3E8tdPtnTTTAroxvi7NDnq5sB6Zaxg9AwDgcuh9tp2Nfcj7U0gfjbDo1wYrdFoIBOAyXsbLe9W2tZqNguq5D+K0tP/NEzIoBYFf3/Cg4hZXP3264n50KxjLOygzhd1vJjswUHmHbCn/V9PYwn1B4PHQPLMT9b3OY72olj3l6DGuzMWp58QkgBB7z9IyisX+BfKilq+LsYsMRv/NyGPkhNiG0FeWvrqKK312MkVk9Cs7yRlh+AVgY38VIg3HHYvHURaHhf2x4Z+j82w4HxY/AtxVd1033ZtVtpKpr/HKHGm7hA7gjMtKLzbY2cEuSXV7Sj7et6JHAzR+tCoFvueo1RxUWZd/wXZ3kWFUPkTWOX8T4twpfV4hRHCf6ZMmpTwH/6+knHbVc972dcXDCLzwQdxV9rJVsqerw3jWOnws85+jXSw57701ORYvZhYmBazOzJykeajXK+MGmt3J8gwA47Op5XXAnYoDdqbm7u7HTIa9bjYsuAS8r+pHvFDb7VJNa+nflC4BmDHkeJ6Bp2DfcM/iFwxwwjz7klCrvSvKuWSTc1UmiokEl8vaGw+6qoQQJOKHwUkkDIIB9cdqq5PVnXWs+czuZHwmcD19Ih8AxUoBmBEOH3wXmFXl8fsij5bKlFJ3UNEwnnrwI/XvgvJZxT0u0Zrzg6XVXwGogJsxraoOwVM3rMfRSNe/yai/Le6JkK77Lms/CDoOBJuP2xeImpXwsghPUO3+DC/xT6P18p2DI5baiG9qpG60xfIEV9Y5fCBzx9CuuGteztsvnIqyuWE+JVpczAJglWlR0Uqup4Qp9xPjMdJiAYkIHSAj51ZUBXGDAGC0rMfBA5Bee5abA667xjxhfbnh/F3o+s8twCRHDY3YBj3m5qbPBCJkjwxOGm4xpZs9wZHiKGYDLmCipCXOYs6VwDt5TM4TPL8aF7Q351EV/0/D6Z/WYZHzD15/RdHHRbJs7MvNAK/lSo3JzHtU7fgAS4OnA2TvXXUf7+8qjO4C2onNEHcKsoxYIHaIOcEarc4rOaLVImAdmlZoBFhTNEfLrGQUMuVMJWFwqggHOnzYvdKUJ+YF/zOWI8p49S4PnJ+/8+PwxIiFg6QI564tQgzHJmGYGsHX1qgWM01r9R+j4jLwpdYo5ryZJiTzunXApYtzUSgorXXzDhyJvhko3+Hca7qeLSkJKdE2cNsLKjTJV+/hFjO/67r3qnd5O+TXh8iXTOSoe28tlPNJw39bqhFZn6J1cJYQY6NA7hUwtlTuXoZemPQqB8MIjUMkbkPNWrlt/h9rBXzaP7htUMJRTCBx29eNToQY8wGVMM28z3GT+qcycWL135gj3dLNdGWeEnsHku4q6K9ob+p2fhEwV9HtLCPvb6fsmNmQ6ulHUPn4e8F1H/Z+j9qQmXromPOGqU0THHXVK0U+0Ql+ZICAmPBD5TcBdnat8qKJaDNRTHfnmLSvZK38eE04SvaEoA454OuJVuyZiPK3VvRc1PeYmcwRszcx2wztTs9vwjx31w/Kpi/JJyJ7xneu6af/1Z0r024vdu6fCSo1BWPX45TdjDrNfvtF2M39+KtxhzKtKndR0gtAEsBSnoGQezKWrOPGuWhnU/jMqATOaTi69MQMST+eXIYtAtNZ1/m7mrza9m1pJS/VWCyWEn+tm+zIzryo0Pnm14ucyQvBy+2l+M3ZGU6zoP8ur9TzgqKaXtc7PYBKqWusZKHE5otuG+KwL/MBRX9wSXJmanZnJbzUj5qmMY8IU8ye66V833Or0wK5W/BLCU76zoOhtrV5x1EmlZoC3NB0nGlytV6kLemELAS7wpYZ7DgRgN/PFGW8FLjfm8tTsyExYpStPVCp+BMwr+uxUAMBdqhh0gQCo1PW6qDICtjG24XztcH4p+6LWiacTwAWqc+pDpeKHpW0nxFgMvs+sghp3OhOi7iR+Qlgj8RPCGomfENZI/ISwRuInhDUSPyGskfgJYY3ETwhrJH5CWCPxE8IaiZ8Q1kj8hLBG4ieENRI/IayR+AlhjcRPCGskfkJYI/ETwhqJnxDWSPyEsEbiJ4Q1ow40OBd3nDMzY1kVIeplLh51ztyR4hdF0UMPPjTiGghRX1EUjfJxYhlAWghL5N5PCGskfkJYI/ETwhqJnxDWSPyEsEbiJ4Q1Ej8hrJH4CWGNxE8IayR+Qlgj8RPCGomfENZI/ISwRuInhDUSPyGskfgJYY3ETwhrJH5CWCPxE8IaiZ8Q1kj8hLBG4ieENRI/IayR+AlhjcRPCGskfkJYI/ETwhqJnxDWSPyEsEbiJ4Q1/w9KlQ0/gO0crAAAAABJRU5ErkJggg==)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M5kyFaVjzXk"
      },
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRYqMAKhExRT"
      },
      "source": [
        "## <font size=\"+2\" color='#154085'><b>5. Data Preparation *(nlp data)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APM_K5pN8Yvo"
      },
      "source": [
        "### 5.1 **description**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxvFuI3M8Pw5"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeHGdjkQ8R7h"
      },
      "outputs": [],
      "source": [
        "df.description.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TsEq81M_fFS"
      },
      "outputs": [],
      "source": [
        "First_des = df.description.iloc[0]\n",
        "First_des"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXXgupGj9LOc"
      },
      "source": [
        "* #### 5.1.1 Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBOYgZwn9WYi"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7giyuFIARRi"
      },
      "outputs": [],
      "source": [
        "! pip install nltk\n",
        "\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p9mx5B193lM"
      },
      "source": [
        "* #### <b>5.1.2 Removing punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4B68C3u99xg"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space,\n",
        "    # which in effect deletes the punctuation marks\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9f1pLMX_Yig"
      },
      "outputs": [],
      "source": [
        "df['description'] = df['description'].apply(remove_punctuation)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkCmPe8UAIrS"
      },
      "source": [
        "* #### <b> 5.1.3 Removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTcp2w0-R3CP"
      },
      "outputs": [],
      "source": [
        "# importing nltk library\n",
        "import nltk\n",
        "# downloading the stopwords from nltk\n",
        "nltk.download('stopwords')\n",
        "# extracting the stopwords from nltk library\n",
        "sw = nltk.corpus.stopwords.words('english')\n",
        "# displaying the stopwords\n",
        "for i in sw:\n",
        "  print(i , end=',  ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-pYkm0oAT4P"
      },
      "outputs": [],
      "source": [
        "# extracting the stopwords from nltk library\n",
        "sw = nltk.corpus.stopwords.words('english')\n",
        "# displaying the stopwords\n",
        "for i in sw:\n",
        "  print(i , end=',  ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFgxZicKAX8D"
      },
      "outputs": [],
      "source": [
        "print(\"Number of stopwords in english : \", len(sw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SqcTupdAcB8"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    #Method 1\n",
        "    text1 = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfkhSswdCMcr"
      },
      "outputs": [],
      "source": [
        "df['description'] = df['description'].apply( remove_stopwords )\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CajZwUewCvF3"
      },
      "source": [
        "Now all the values of description are punctutation free ans stopword free"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LBR_h3TC7Oa"
      },
      "source": [
        "* #### 5.1.4 Using **CountVectorizer()** to count vocabulary items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vqd8ZnuDDL3"
      },
      "outputs": [],
      "source": [
        "# Create a count vectorizer object\n",
        "count_vectorizer = CountVectorizer()\n",
        "# fit the count vectorizer using the text data\n",
        "count_vectorizer.fit(df['description'])\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = count_vectorizer.vocabulary_.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFGZ7OOuDNzY"
      },
      "outputs": [],
      "source": [
        "dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cd3f5L8Db0e"
      },
      "outputs": [],
      "source": [
        "vocab = [ ]\n",
        "count_of_vocab = []\n",
        "for key , value in dictionary:\n",
        "  vocab.append( key )\n",
        "  count_of_vocab.append( value )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_chBWH_PENWX"
      },
      "source": [
        "* Creating a new *DataFrame* **vocab_before_stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVGzZ-xlER6o"
      },
      "outputs": [],
      "source": [
        "# Store the count in panadas dataframe with vocab as index\n",
        "vocab_before_stemming = pd.DataFrame({\"Word\": vocab ,\n",
        "                                      \"count\" :count_of_vocab})\n",
        "# Sort the dataframe\n",
        "vocab_before_stemming = vocab_before_stemming.sort_values(\"count\" ,ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQmRrShtE4nH"
      },
      "outputs": [],
      "source": [
        "vocab_before_stemming.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Njvt0TVmI9Gm"
      },
      "outputs": [],
      "source": [
        "vocab_before_stemming.head(20).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0spMBJEFBsH"
      },
      "outputs": [],
      "source": [
        "vocab_before_stemming.tail(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8xLwj4JGhNS"
      },
      "source": [
        "* TOP 10 most occurred words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IypTeEiwGkq3"
      },
      "outputs": [],
      "source": [
        "top15_most_ocurred_vacab = vocab_before_stemming.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZxkH3QMHzhO"
      },
      "outputs": [],
      "source": [
        "top15_most_occurred_words = top15_most_ocurred_vacab.Word.values\n",
        "top15_most_occurred_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8a8KhAyH7dt"
      },
      "outputs": [],
      "source": [
        "top15_most_occurred_words_count = top15_most_ocurred_vacab['count'].values\n",
        "top15_most_occurred_words_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJxxssQ2IHIa"
      },
      "outputs": [],
      "source": [
        "plt.figure( figsize = ( 16,6 ))\n",
        "plt.xlim(19550, 19600)\n",
        "plt.barh(top15_most_occurred_words , top15_most_occurred_words_count )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClN2_Q_hKBsG"
      },
      "source": [
        "* #### 5.1.5 Now will use **SnowballStemmer( 'english' )**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc5UDvVRKSm5"
      },
      "outputs": [],
      "source": [
        "# Create an object of stemming function\n",
        "stemmer = SnowballStemmer(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiCBDwRnKLkl"
      },
      "outputs": [],
      "source": [
        "def Apply_stemming(text):\n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLkY0xN4KanQ"
      },
      "outputs": [],
      "source": [
        "#Stemming for description\n",
        "df['description'] = df['description'].apply( Apply_stemming )\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeriPl_sKl2A"
      },
      "source": [
        "* #### 5.1.6 Now again will use **TfidfVectorizer** *(after stemming)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78DaVhk3KuKL"
      },
      "outputs": [],
      "source": [
        "# Create the object of tfid vectorizer\n",
        "tfid_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer using the text data\n",
        "tfid_vectorizer.fit(df['description'])\n",
        "\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfid_vectorizer.vocabulary_.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOgK9svDLK-s"
      },
      "outputs": [],
      "source": [
        "# Lists to store the vocab and counts\n",
        "vocab = []\n",
        "count_of_vocab = []\n",
        "# Iterate through each vocab and count append the value to designated lists\n",
        "for key, value in dictionary:\n",
        "    vocab.append(key)\n",
        "    count_of_vocab.append(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G_ksZBcLhwh"
      },
      "source": [
        "* Creating a new *DataFrame* **vocab_after_stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "natYzOYzLbE8"
      },
      "outputs": [],
      "source": [
        "# Store the count in panadas dataframe with vocab as index\n",
        "vocab_after_stemming = pd.DataFrame({\"Word\": vocab ,\n",
        "                                      \"count\" :count_of_vocab})\n",
        "# Sort the dataframe\n",
        "vocab_after_stemming = vocab_after_stemming.sort_values(\"count\" ,ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JANSMFQnL6_q"
      },
      "outputs": [],
      "source": [
        "top15_most_ocurred_vocab = vocab_after_stemming.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl-G-PpqL-g6"
      },
      "outputs": [],
      "source": [
        "top15_most_occurred_words = top15_most_ocurred_vocab.Word.values\n",
        "top15_most_occurred_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt8Hn5NDL69B"
      },
      "outputs": [],
      "source": [
        "top15_most_occurred_words_count = top15_most_ocurred_vocab['count'].values\n",
        "top15_most_occurred_words_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiWAoigGL66N"
      },
      "outputs": [],
      "source": [
        "plt.figure( figsize = ( 16,6 ))\n",
        "plt.xlim(14225, 14241)\n",
        "plt.barh(top15_most_occurred_words , top15_most_occurred_words_count )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgU4_iXFNHTr"
      },
      "source": [
        "* #### 5.1.7 Adding a new column **length** which will contain length of description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH315H5mNVQ0"
      },
      "outputs": [],
      "source": [
        "df['Length(description)'] = df['description'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyHjYs65Nddi"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7mbUfooNhQO"
      },
      "outputs": [],
      "source": [
        "df.description.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlRdsN7sNkaM"
      },
      "outputs": [],
      "source": [
        "len(df.description.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kywAd8sEN4nr"
      },
      "source": [
        "* ### 5.2 **listed_in**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVFczhLON98g"
      },
      "source": [
        "* #### 5.2.1 Removing punctutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxis3XLMOIr6"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsjwmmU9OHBF"
      },
      "outputs": [],
      "source": [
        "df['listed_in'] = df['listed_in'].apply(remove_punctuation)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKY4rnoVOWBO"
      },
      "source": [
        "* #### 5.2.2 Removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukMcdLWJOWbr"
      },
      "outputs": [],
      "source": [
        "#Remove stopwords for listed_in\n",
        "df['listed_in'] = df['listed_in'].apply( remove_stopwords )\n",
        "df.head( 2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7WhR1MHOwJ2"
      },
      "source": [
        "* #### 5.2.3 Using **CountVectorizer()** to count vocabulary items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NThHZGMXO0un"
      },
      "outputs": [],
      "source": [
        "# Create a count vectorizer object\n",
        "count_vectorizer = CountVectorizer()\n",
        "# fit the count vectorizer using the text data\n",
        "count_vectorizer.fit(df['listed_in'])\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = count_vectorizer.vocabulary_.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQRI-spTO5E_"
      },
      "outputs": [],
      "source": [
        "dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAiAGAz0O48k"
      },
      "outputs": [],
      "source": [
        "vocab = [ ]\n",
        "count_of_vocab = []\n",
        "for key , value in dictionary:\n",
        "  vocab.append( key )\n",
        "  count_of_vocab.append( value )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDktmlUtPIyd"
      },
      "outputs": [],
      "source": [
        "listed_in_vocab_before_stem = pd.DataFrame({\"Word\": vocab , \"count\" :count_of_vocab})\n",
        "\n",
        "listed_in_vocab_before_stem = listed_in_vocab_before_stem.sort_values(\"count\" ,ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRwMyA0uPgXb"
      },
      "outputs": [],
      "source": [
        "listed_in_vocab_before_stem.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiOWZDX3Pjaw"
      },
      "outputs": [],
      "source": [
        "listed_in_vocab_before_stem.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_DAlx8PPrZu"
      },
      "source": [
        "* TOP 10 most occurred words in listed in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkF-7G7FPlxT"
      },
      "outputs": [],
      "source": [
        "top15_most_ocurred_vocab_listed_in = listed_in_vocab_before_stem.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyi8qBFFP0qW"
      },
      "outputs": [],
      "source": [
        "top15_most_ocurred_words_listed_in = top15_most_ocurred_vocab_listed_in.Word.values\n",
        "top15_most_ocurred_words_listed_in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqLAcfWaP0aE"
      },
      "outputs": [],
      "source": [
        "top15_most_occurred_words_in_listed_in_count = top15_most_ocurred_vocab_listed_in['count'].values\n",
        "top15_most_occurred_words_in_listed_in_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvTpJ-fHP0XX"
      },
      "outputs": [],
      "source": [
        "plt.figure( figsize = ( 10,6 ))\n",
        "plt.xlim(25, 42 )\n",
        "plt.barh(top15_most_ocurred_words_listed_in , top15_most_occurred_words_in_listed_in_count )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvV_PyKTQvh-"
      },
      "source": [
        "* #### 5.2.4 Now will use **SnowballStemmer( 'english' )**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfmp_s_FP0Ui"
      },
      "outputs": [],
      "source": [
        "#Stemming for description\n",
        "df['listed_in'] = df['listed_in'].apply( Apply_stemming )\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK9Yg0jnQ8--"
      },
      "source": [
        "* #### 5.2.5 Now will use **TfidfVectorizer** *(after stemming)*( TFIDF ) Bag Of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx8xX79DP0R7"
      },
      "outputs": [],
      "source": [
        "# Create the object of tfid vectorizer\n",
        "tfid_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer using the text data\n",
        "tfid_vectorizer.fit(df['listed_in'])\n",
        "\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = tfid_vectorizer.vocabulary_.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDt4Km3oSD-x"
      },
      "outputs": [],
      "source": [
        "dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRVcUrBGRDx_"
      },
      "outputs": [],
      "source": [
        "# Lists to store the vocab and counts\n",
        "vocab = []\n",
        "count_of_vocab = []\n",
        "# Iterate through each vocab and count append the value to designated lists\n",
        "for key, value in dictionary:\n",
        "    vocab.append(key)\n",
        "    count_of_vocab.append(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_4phns2RIXs"
      },
      "source": [
        "* Creating a new *DataFrame* **vocab_after_stemming_listed_in**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LRInvJ_RLTV"
      },
      "outputs": [],
      "source": [
        "vocab_after_stemming_listed_in = pd.DataFrame({\"Word\": vocab , \"count\" :count_of_vocab})\n",
        "# Sort the dataframe by count\n",
        "vocab_after_stemming_listed_in = vocab_after_stemming_listed_in.sort_values(\"count\" ,ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tum3gga9RnKm"
      },
      "outputs": [],
      "source": [
        "top15_most_ocurred_vocab_lised_in_after_stem = vocab_after_stemming_listed_in.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo71I6pPRVy9"
      },
      "outputs": [],
      "source": [
        "top15_most_ocurred_vocab_lised_in_after_stem_word = top15_most_ocurred_vocab_lised_in_after_stem.Word.values\n",
        "top15_most_ocurred_vocab_lised_in_after_stem_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9eAOtezSPCl"
      },
      "outputs": [],
      "source": [
        "top15_most_occurred_words_listed_in_count = top15_most_ocurred_vocab_lised_in_after_stem['count'].values\n",
        "top15_most_occurred_words_listed_in_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1XQwCk2RWFV"
      },
      "source": [
        "* Plot of the top vocab present in listed_in (after stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPXq6zTmSZQR"
      },
      "outputs": [],
      "source": [
        "plt.figure( figsize = ( 10,6 ))\n",
        "plt.xlim(25, 40 )\n",
        "plt.barh(top15_most_ocurred_vocab_lised_in_after_stem_word , top15_most_occurred_words_listed_in_count )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S15BI4zS89h"
      },
      "source": [
        "* #### 5.2.6 Adding a new column **length( listed-in )** which will contain length of listed_in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIjQIIAKS8ng"
      },
      "outputs": [],
      "source": [
        "df['Length(listed-in)'] = df['listed_in'].apply(lambda x: len(x))\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jXvNt02TeN6"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNwZusJeTc06"
      },
      "outputs": [],
      "source": [
        "df[['description', 'Length(description)', 'listed_in' ,'Length(listed-in)' ]].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBrYaKLQzXsJ"
      },
      "source": [
        "\n",
        "##Exploratory Data Analysis Conclusions\n",
        "---\n",
        "---\n",
        "> * **Netflix began adding videos to the platform from 2008**\n",
        "> * **The streaming giant started aggressively adding movies and TV shows from 2017**\n",
        "> * **More movies are added as compared to TV shows**\n",
        "---\n",
        "> * **There are almost twice as many movies as TV shows on Netflix.**\n",
        "---\n",
        "> * **Most content on Netflix is rated for Mature Audiences and over 14 years old**\n",
        "---\n",
        "> **Top Countries in Netflix are:**\n",
        "1. **United States**\n",
        "2. **India**\n",
        "3. **United Kingdom**\n",
        "4. **Canada**\n",
        "5. **France**\n",
        "\n",
        "---\n",
        "> **Top Genres in Netflix are:**\n",
        "1. **Drama**\n",
        "2.**Comedy**\n",
        "3.**Documentary**\n",
        "4.**Action and Adventure**\n",
        "5.**Romance**\n",
        "\n",
        "---\n",
        "> **Top Directors on Netflix are:**\n",
        "1. **Jan Suter**\n",
        "2.**Raul Campos**\n",
        "3.**Marcus Raboy**\n",
        "4.**Jay Karas**\n",
        "5.**Cathy Garcia-Molina**\n",
        "\n",
        "---\n",
        "> **Top Actors on Netflix are:**\n",
        "1. **Anupam Kher**\n",
        "2.**Shah Rukh Khan**\n",
        "3.**Naseeruddin Shah**\n",
        "4.**Om Puri**\n",
        "5.**Akshay Kumar**\n",
        "\n",
        "---\n",
        "> * **Most movies on Netflix have a duration range from 90 to 110 minutes**\n",
        "---\n",
        "> * **Most TV shows on Netflix have a span of only one season**.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Th00DnEd9D"
      },
      "source": [
        "## <font size='+2' color = '#154085'> <B> End Conclusion.</b>\n",
        "\n",
        "1. Director and cast contains a large number of null values so we will drop these 2 columns .\n",
        "2. In this dataset there are two types of contents where 30.86% includes TV shows and the\n",
        "remaining 69.14% carries Movies.\n",
        "3. We have reached a conclusion from our analysis from the content added over years that\n",
        "Netflix is focusing movies and TV shows (Fom 2016 data we get to know that Movies is\n",
        "increased by 80% and TV shows is increased by 73% compare)\n",
        "4. From the dataset insights we can conclude that the most number of TV Shows released in\n",
        "2017 and for Movies it is 2020\n",
        "5. On Netflix USA has the largest number of contents. And most of the countries preferred to\n",
        "produce movies more than TV shows.\n",
        "6. Most of the movies are belonging to 3 categories\n",
        "7. TOP 3 content categories are International movies , dramas , comedies.\n",
        "8. In text analysis (NLP) I used stop words, removed punctuations , stemming & TF-IDF\n",
        "vectorizer and other functions of NLP.\n",
        "9. Applied different clustering models like Kmeans, hierarchical, Agglomerative clustering,\n",
        "DBSCAN on data we got the best cluster arrangements.\n",
        "10.By applying different clustering algorithms to our dataset .we get the optimal number of\n",
        "cluster is equal to 3\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}